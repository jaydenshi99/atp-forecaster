{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048e9e8c",
   "metadata": {},
   "source": [
    "## Backtesting Data\n",
    "\n",
    "Currently, I am working with Jeff Sackman's ATP dataset. However, for backtesting I need bookmaker odds, which is not included in this data. I've found another dataset that includes the bookmaker odds. The aim of this dataset is to combine the two to form a dataset that can be used for backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc490346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# List of xls years\n",
    "start_year = 2001\n",
    "end_year = 2024\n",
    "files = []\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    base_path = f\"../../data/raw/tennis-data/{year}\"\n",
    "    \n",
    "    xls_path = base_path + \".xls\"\n",
    "    xlsx_path = base_path + \".xlsx\"\n",
    "    \n",
    "    if os.path.exists(xls_path):\n",
    "        files.append(xls_path)\n",
    "    elif os.path.exists(xlsx_path):\n",
    "        files.append(xlsx_path)\n",
    "    else:\n",
    "        print(f\"Warning: no file found for year {year} ({xls_path} or {xlsx_path})\")\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files, read each one, and append to the list\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list vertically (stacking rows)\n",
    "odds_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "sackman_df = pd.read_parquet(\"../../data/training_data/dataset_v1_full.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1f2b62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['surface', 'draw_size', 'tourney_level', 'tourney_date', 'id_a',\n",
       "       'name_a', 'hand_a', 'ht_a', 'age_a', 'id_b', 'name_b', 'hand_b', 'ht_b',\n",
       "       'age_b', 'score', 'best_of', 'round', 'minutes', 'ace_a', 'df_a',\n",
       "       'svpt_a', '1stIn_a', '1stWon_a', '2ndWon_a', 'SvGms_a', 'bpSaved_a',\n",
       "       'bpFaced_a', 'ace_b', 'df_b', 'svpt_b', '1stIn_b', '1stWon_b',\n",
       "       '2ndWon_b', 'SvGms_b', 'bpSaved_b', 'bpFaced_b', 'rank_a',\n",
       "       'rank_points_a', 'rank_b', 'rank_points_b', 'result', 'p_ace_a',\n",
       "       'p_ace_b', 'p_df_a', 'p_df_b', 'p_1stIn_a', 'p_1stIn_b', 'p_1stWon_a',\n",
       "       'p_1stWon_b', 'p_2ndWon_a', 'p_2ndWon_b', 'p_2ndWon_inPlay_a',\n",
       "       'p_2ndWon_inPlay_b', 'p_bpSaved_a', 'p_bpSaved_b', 'p_rpw_a', 'p_rpw_b',\n",
       "       'p_retAceAgainst_a', 'p_retAceAgainst_b', 'p_ret1stWon_a',\n",
       "       'p_ret1stWon_b', 'p_ret2ndWon_a', 'p_ret2ndWon_b',\n",
       "       'p_ret2ndWon_inPlay_a', 'p_ret2ndWon_inPlay_b', 'p_bpConv_a',\n",
       "       'p_bpConv_b', 'p_totalPtsWon_a', 'p_totalPtsWon_b', 'dominance_ratio_a',\n",
       "       'dominance_ratio_b', 'elo_a', 'elo_b', 'elo_surface_a', 'elo_surface_b',\n",
       "       'total_matches_a', 'total_matches_b', 'total_surface_matches_a',\n",
       "       'total_surface_matches_b', 'recent_matches_a', 'recent_matches_b',\n",
       "       'recent_minutes_a', 'recent_minutes_b', 'hth_win_p_a', 'hth_matches',\n",
       "       'form_delta_a', 'form_delta_b', 'elo_momentum_a', 'elo_momentum_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sackman_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "64d234e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATP', 'Location', 'Tournament', 'Date', 'Series', 'Court', 'Surface',\n",
       "       'Round', 'Best of', 'Winner', 'Loser', 'WRank', 'LRank', 'W1', 'L1',\n",
       "       'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', 'Wsets', 'Lsets',\n",
       "       'Comment', 'CBW', 'CBL', 'GBW', 'GBL', 'IWW', 'IWL', 'SBW', 'SBL',\n",
       "       'B365W', 'B365L', 'B&WW', 'B&WL', 'EXW', 'EXL', 'PSW', 'PSL', 'WPts',\n",
       "       'LPts', 'UBW', 'UBL', 'LBW', 'LBL', 'SJW', 'SJL', 'MaxW', 'MaxL',\n",
       "       'AvgW', 'AvgL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d83562",
   "metadata": {},
   "source": [
    "There are a few rows that can be used as merge points.\n",
    "1. Winner Name\n",
    "2. Loser Name\n",
    "3. Date\n",
    "4. Surface\n",
    "5. Best of\n",
    "6. Set scores\n",
    "\n",
    "Winner name, loser name and date will be able to match more than 99% of the rows. Duplicate matchings will be removed.\n",
    "\n",
    "Name old format: Firstname Lastname\n",
    "\n",
    "Name new format: Lastname FirstInitial.\n",
    "\n",
    "The old name will be converted to the new format.\n",
    "\n",
    "Date old format: YYYYMMDD rounded to the first monday\n",
    "\n",
    "Date new format: YYYY-MM-DD precise day of match\n",
    "\n",
    "The new date will be rounded to the most recent monday for merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8ab5edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def old_to_new_name(name):\n",
    "    \"\"\"\n",
    "    Convert 'Firstname Lastname' -> 'Lastname F.'\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return np.nan\n",
    "    parts = name.split()\n",
    "    if len(parts) < 2:\n",
    "        return name\n",
    "    first, last = parts[0], \" \".join(parts[1:])\n",
    "    initial = first[0].upper()\n",
    "    return f\"{last} {initial}.\"\n",
    "\n",
    "def new_to_old_name(name, old_name_lookup):\n",
    "    \"\"\"\n",
    "    Convert 'Lastname F.' -> approximate 'Firstname Lastname' via lookup table.\n",
    "    If not found, returns original.\n",
    "    \"\"\"\n",
    "    return old_name_lookup.get(name, name)\n",
    "\n",
    "def monday_round(date_obj):\n",
    "    \"\"\"\n",
    "    Round a date down to the most recent Monday.\n",
    "    \"\"\"\n",
    "    if isinstance(date_obj, str):\n",
    "        date_obj = pd.to_datetime(date_obj)\n",
    "    return date_obj - timedelta(days=date_obj.weekday())\n",
    "\n",
    "def yyyymmdd_to_monday(yyyymmdd):\n",
    "    \"\"\"\n",
    "    Convert YYYYMMDD integer into datetime, then round to Monday.\n",
    "    \"\"\"\n",
    "    if pd.isna(yyyymmdd):\n",
    "        return np.nan\n",
    "    s = str(int(yyyymmdd))\n",
    "    dt = datetime.strptime(s, \"%Y%m%d\")\n",
    "    return monday_round(dt)\n",
    "\n",
    "def merge_old_new(old_df, new_df):\n",
    "    df_old = old_df.copy()\n",
    "    df_new = new_df.copy()\n",
    "\n",
    "    df_old[\"name_a_new\"] = df_old[\"name_a\"].apply(old_to_new_name)\n",
    "    df_old[\"name_b_new\"] = df_old[\"name_b\"].apply(old_to_new_name)\n",
    "\n",
    "    # find winner and loser names\n",
    "    df_old[\"old_winner\"] = np.where(df_old[\"result\"] == 1,\n",
    "                                df_old[\"name_a_new\"],\n",
    "                                df_old[\"name_b_new\"])\n",
    "\n",
    "    df_old[\"old_loser\"] = np.where(df_old[\"result\"] == 1,\n",
    "                                df_old[\"name_b_new\"],\n",
    "                                df_old[\"name_a_new\"])\n",
    "\n",
    "    # For new_df, Winner/Loser are already in Lastname F. format → keep them\n",
    "    df_new.rename(columns={\"Winner\": \"winner_new\",\n",
    "                           \"Loser\": \"loser_new\"}, inplace=True)\n",
    "\n",
    "    # old_df tourney_date → Monday\n",
    "    df_old[\"merge_date\"] = df_old[\"tourney_date\"].apply(yyyymmdd_to_monday)\n",
    "\n",
    "    # new_df Date (YYYY-MM-DD) → round to Monday\n",
    "    df_new[\"merge_date\"] = df_new[\"Date\"].apply(lambda d: monday_round(pd.to_datetime(d)))\n",
    "\n",
    "    df_old[\"surface_norm\"] = df_old[\"surface\"].str.lower().str.strip()\n",
    "    df_old[\"best_of_norm\"] = df_old[\"best_of\"].astype(\"Int64\")\n",
    "\n",
    "    df_new[\"surface_norm\"] = df_new[\"Surface\"].str.lower().str.strip()\n",
    "    df_new[\"best_of_norm\"] = df_new[\"Best of\"].astype(\"Int64\")\n",
    "\n",
    "    merge_cols_old = [\"old_winner\", \"old_loser\", \"merge_date\",\n",
    "                      \"surface_norm\", \"best_of_norm\"]\n",
    "\n",
    "    merge_cols_new = [\"winner_new\", \"loser_new\", \"merge_date\",\n",
    "                      \"surface_norm\", \"best_of_norm\"]\n",
    "\n",
    "    merged = df_old.merge(\n",
    "        df_new,\n",
    "        left_on=merge_cols_old,\n",
    "        right_on=merge_cols_new,\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_old\", \"_new\")\n",
    "    )\n",
    "\n",
    "    key_cols = [\"id_a\", \"id_b\", \"merge_date\"]\n",
    "    dup_mask = merged.duplicated(subset=key_cols, keep=False)\n",
    "\n",
    "    # keep non duplicated rows\n",
    "    merged = merged[~dup_mask].copy()\n",
    "\n",
    "    # remove rows with no odds\n",
    "    odds_cols = [\"PSW\", \"PSL\", \"B365W\", \"B365L\", \"IWW\", \"IWL\"]\n",
    "    merged = merged.dropna(subset=odds_cols, how=\"all\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in sackman_df 63739\n",
      "rows in merged_df 44136\n",
      "percent lost 0.30755110685765386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = merge_old_new(sackman_df, odds_df)\n",
    "\n",
    "og_rows = odds_df.shape[0]\n",
    "merged_rows = merged_df.shape[0]\n",
    "\n",
    "print(\"rows in sackman_df\", og_rows)\n",
    "print(\"rows in merged_df\", merged_rows)\n",
    "print(\"percent lost\", (og_rows - merged_rows) / og_rows)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
