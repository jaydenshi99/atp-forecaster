{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "048e9e8c",
   "metadata": {},
   "source": [
    "## Backtesting Data\n",
    "\n",
    "Currently, I am working with Jeff Sackman's ATP dataset. However, for backtesting I need bookmaker odds, which is not included in this data. I've found another dataset that includes the bookmaker odds. The aim of this dataset is to combine the two to form a dataset that can be used for backtesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fc490346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openpyxl/worksheet/_reader.py:329: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# List of xls years\n",
    "start_year = 2001\n",
    "end_year = 2024\n",
    "files = []\n",
    "\n",
    "for year in range(start_year, end_year + 1):\n",
    "    base_path = f\"../../data/raw/tennis-data/{year}\"\n",
    "    \n",
    "    xls_path = base_path + \".xls\"\n",
    "    xlsx_path = base_path + \".xlsx\"\n",
    "    \n",
    "    if os.path.exists(xls_path):\n",
    "        files.append(xls_path)\n",
    "    elif os.path.exists(xlsx_path):\n",
    "        files.append(xlsx_path)\n",
    "    else:\n",
    "        print(f\"Warning: no file found for year {year} ({xls_path} or {xlsx_path})\")\n",
    "\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop through the files, read each one, and append to the list\n",
    "for file in files:\n",
    "    df = pd.read_excel(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames in the list vertically (stacking rows)\n",
    "odds_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "sackman_df = pd.read_parquet(\"../../data/features/feature_sets/dataset_v1_combined.parquet\")\n",
    "\n",
    "# fix error in EXW\n",
    "odds_df[\"EXW\"] = (\n",
    "    odds_df[\"EXW\"]\n",
    "    .replace({\",\": \"\"}, regex=True)\n",
    "    .replace(\"\", np.nan)\n",
    "    .astype(float)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a1f2b62d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['surface', 'draw_size', 'tourney_level', 'tourney_date', 'id_a',\n",
       "       'name_a', 'hand_a', 'ht_a', 'age_a', 'id_b', 'name_b', 'hand_b', 'ht_b',\n",
       "       'age_b', 'score', 'best_of', 'round', 'minutes', 'ace_a', 'df_a',\n",
       "       'svpt_a', '1stIn_a', '1stWon_a', '2ndWon_a', 'SvGms_a', 'bpSaved_a',\n",
       "       'bpFaced_a', 'ace_b', 'df_b', 'svpt_b', '1stIn_b', '1stWon_b',\n",
       "       '2ndWon_b', 'SvGms_b', 'bpSaved_b', 'bpFaced_b', 'rank_a',\n",
       "       'rank_points_a', 'rank_b', 'rank_points_b', 'result', 'p_ace_a',\n",
       "       'p_ace_b', 'p_df_a', 'p_df_b', 'p_1stIn_a', 'p_1stIn_b', 'p_1stWon_a',\n",
       "       'p_1stWon_b', 'p_2ndWon_a', 'p_2ndWon_b', 'p_2ndWon_inPlay_a',\n",
       "       'p_2ndWon_inPlay_b', 'p_bpSaved_a', 'p_bpSaved_b', 'p_rpw_a', 'p_rpw_b',\n",
       "       'p_retAceAgainst_a', 'p_retAceAgainst_b', 'p_ret1stWon_a',\n",
       "       'p_ret1stWon_b', 'p_ret2ndWon_a', 'p_ret2ndWon_b',\n",
       "       'p_ret2ndWon_inPlay_a', 'p_ret2ndWon_inPlay_b', 'p_bpConv_a',\n",
       "       'p_bpConv_b', 'p_totalPtsWon_a', 'p_totalPtsWon_b', 'dominance_ratio_a',\n",
       "       'dominance_ratio_b', 'elo_a', 'elo_b', 'elo_surface_a', 'elo_surface_b',\n",
       "       'total_matches_a', 'total_matches_b', 'total_surface_matches_a',\n",
       "       'total_surface_matches_b', 'recent_matches_a', 'recent_matches_b',\n",
       "       'recent_minutes_a', 'recent_minutes_b', 'hth_win_p_a', 'hth_matches',\n",
       "       'form_delta_a', 'form_delta_b', 'elo_momentum_a', 'elo_momentum_b'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sackman_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "64d234e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ATP', 'Location', 'Tournament', 'Date', 'Series', 'Court', 'Surface',\n",
       "       'Round', 'Best of', 'Winner', 'Loser', 'WRank', 'LRank', 'W1', 'L1',\n",
       "       'W2', 'L2', 'W3', 'L3', 'W4', 'L4', 'W5', 'L5', 'Wsets', 'Lsets',\n",
       "       'Comment', 'CBW', 'CBL', 'GBW', 'GBL', 'IWW', 'IWL', 'SBW', 'SBL',\n",
       "       'B365W', 'B365L', 'B&WW', 'B&WL', 'EXW', 'EXL', 'PSW', 'PSL', 'WPts',\n",
       "       'LPts', 'UBW', 'UBL', 'LBW', 'LBL', 'SJW', 'SJL', 'MaxW', 'MaxL',\n",
       "       'AvgW', 'AvgL'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odds_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d83562",
   "metadata": {},
   "source": [
    "There are a few rows that can be used as merge points.\n",
    "1. Winner Name\n",
    "2. Loser Name\n",
    "3. Date\n",
    "4. Surface\n",
    "5. Best of\n",
    "6. Set scores\n",
    "\n",
    "Winner name, loser name and date will be able to the majority of the rows. Duplicate matchings will be completely removed to avoid incorrect data.\n",
    "\n",
    "Name old format: Firstname Lastname\n",
    "\n",
    "Name new format: Lastname FirstInitial.\n",
    "\n",
    "The old name will be converted to the new format.\n",
    "\n",
    "Date old format: YYYYMMDD rounded to the first monday\n",
    "\n",
    "Date new format: YYYY-MM-DD precise day of match\n",
    "\n",
    "The new date will be rounded to the most recent monday for merging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ab5edc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def old_to_new_name(name):\n",
    "    \"\"\"\n",
    "    Convert 'Firstname Lastname' -> 'Lastname F.'\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return np.nan\n",
    "    parts = name.split()\n",
    "    if len(parts) < 2:\n",
    "        return name\n",
    "    first, last = parts[0], \" \".join(parts[1:])\n",
    "    initial = first[0].upper()\n",
    "    return f\"{last} {initial}.\"\n",
    "\n",
    "def new_to_old_name(name, old_name_lookup):\n",
    "    \"\"\"\n",
    "    Convert 'Lastname F.' -> approximate 'Firstname Lastname' via lookup table.\n",
    "    If not found, returns original.\n",
    "    \"\"\"\n",
    "    return old_name_lookup.get(name, name)\n",
    "\n",
    "def monday_round(date_obj):\n",
    "    \"\"\"\n",
    "    Round a date down to the most recent Monday.\n",
    "    \"\"\"\n",
    "    if isinstance(date_obj, str):\n",
    "        date_obj = pd.to_datetime(date_obj)\n",
    "    return date_obj - timedelta(days=date_obj.weekday())\n",
    "\n",
    "def yyyymmdd_to_monday(yyyymmdd):\n",
    "    \"\"\"\n",
    "    Convert YYYYMMDD integer into datetime, then round to Monday.\n",
    "    \"\"\"\n",
    "    if pd.isna(yyyymmdd):\n",
    "        return np.nan\n",
    "    s = str(int(yyyymmdd))\n",
    "    dt = datetime.strptime(s, \"%Y%m%d\")\n",
    "    return monday_round(dt)\n",
    "\n",
    "def merge_old_new(old_df, new_df):\n",
    "    df_old = old_df.copy()\n",
    "    df_new = new_df.copy()\n",
    "\n",
    "    df_old[\"name_a_new\"] = df_old[\"name_a\"].apply(old_to_new_name)\n",
    "    df_old[\"name_b_new\"] = df_old[\"name_b\"].apply(old_to_new_name)\n",
    "\n",
    "    # find winner and loser names\n",
    "    df_old[\"old_winner\"] = np.where(df_old[\"result\"] == 1,\n",
    "                                df_old[\"name_a_new\"],\n",
    "                                df_old[\"name_b_new\"])\n",
    "\n",
    "    df_old[\"old_loser\"] = np.where(df_old[\"result\"] == 1,\n",
    "                                df_old[\"name_b_new\"],\n",
    "                                df_old[\"name_a_new\"])\n",
    "\n",
    "    # For new_df, Winner/Loser are already in Lastname F. format → keep them\n",
    "    df_new.rename(columns={\"Winner\": \"winner_new\",\n",
    "                           \"Loser\": \"loser_new\"}, inplace=True)\n",
    "\n",
    "    # old_df tourney_date → Monday\n",
    "    df_old[\"merge_date\"] = df_old[\"tourney_date\"].apply(yyyymmdd_to_monday)\n",
    "\n",
    "    # new_df Date (YYYY-MM-DD) → round to Monday\n",
    "    df_new[\"merge_date\"] = df_new[\"Date\"].apply(lambda d: monday_round(pd.to_datetime(d)))\n",
    "\n",
    "    df_old[\"surface_norm\"] = df_old[\"surface\"].str.lower().str.strip()\n",
    "    df_old[\"best_of_norm\"] = df_old[\"best_of\"].astype(\"Int64\")\n",
    "\n",
    "    df_new[\"surface_norm\"] = df_new[\"Surface\"].str.lower().str.strip()\n",
    "    df_new[\"best_of_norm\"] = df_new[\"Best of\"].astype(\"Int64\")\n",
    "\n",
    "    merge_cols_old = [\"old_winner\", \"old_loser\", \"merge_date\",\n",
    "                      \"surface_norm\", \"best_of_norm\"]\n",
    "\n",
    "    merge_cols_new = [\"winner_new\", \"loser_new\", \"merge_date\",\n",
    "                      \"surface_norm\", \"best_of_norm\"]\n",
    "\n",
    "    merged = df_old.merge(\n",
    "        df_new,\n",
    "        left_on=merge_cols_old,\n",
    "        right_on=merge_cols_new,\n",
    "        how=\"left\",\n",
    "        suffixes=(\"_old\", \"_new\")\n",
    "    )\n",
    "\n",
    "    key_cols = [\"id_a\", \"id_b\", \"merge_date\"]\n",
    "    dup_mask = merged.duplicated(subset=key_cols, keep=False)\n",
    "\n",
    "    # keep non duplicated rows\n",
    "    merged = merged[~dup_mask].copy()\n",
    "\n",
    "    # remove rows with no odds\n",
    "    odds_cols = ['CBW', 'CBL', 'GBW', 'GBL', 'IWW', 'IWL', 'SBW', 'SBL',\n",
    "       'B365W', 'B365L', 'B&WW', 'B&WL', 'EXW', 'EXL', 'PSW', 'PSL']\n",
    "    merged = merged.dropna(subset=odds_cols, how=\"all\")\n",
    "\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b19d0f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows in sackman_df 63739\n",
      "rows in merged_df 44217\n",
      "percent lost 0.30628029934576945\n",
      "surface                        0\n",
      "draw_size                      0\n",
      "tourney_level                  0\n",
      "tourney_date                   0\n",
      "id_a                           0\n",
      "name_a                         0\n",
      "hand_a                         0\n",
      "ht_a                           0\n",
      "age_a                          0\n",
      "id_b                           0\n",
      "name_b                         0\n",
      "hand_b                         0\n",
      "ht_b                           0\n",
      "age_b                          0\n",
      "score                          0\n",
      "best_of                        0\n",
      "round                          0\n",
      "minutes                        0\n",
      "ace_a                          0\n",
      "df_a                           0\n",
      "svpt_a                         0\n",
      "1stIn_a                        0\n",
      "1stWon_a                       0\n",
      "2ndWon_a                       0\n",
      "SvGms_a                        0\n",
      "bpSaved_a                      0\n",
      "bpFaced_a                      0\n",
      "ace_b                          0\n",
      "df_b                           0\n",
      "svpt_b                         0\n",
      "1stIn_b                        0\n",
      "1stWon_b                       0\n",
      "2ndWon_b                       0\n",
      "SvGms_b                        0\n",
      "bpSaved_b                      0\n",
      "bpFaced_b                      0\n",
      "rank_a                         0\n",
      "rank_points_a                  0\n",
      "rank_b                         0\n",
      "rank_points_b                  0\n",
      "result                         0\n",
      "p_ace_a                        0\n",
      "p_ace_b                        0\n",
      "p_df_a                         0\n",
      "p_df_b                         0\n",
      "p_1stIn_a                      0\n",
      "p_1stIn_b                      0\n",
      "p_1stWon_a                     0\n",
      "p_1stWon_b                     0\n",
      "p_2ndWon_a                     0\n",
      "p_2ndWon_b                     0\n",
      "p_2ndWon_inPlay_a              0\n",
      "p_2ndWon_inPlay_b              0\n",
      "p_bpSaved_a                    0\n",
      "p_bpSaved_b                    0\n",
      "p_rpw_a                        0\n",
      "p_rpw_b                        0\n",
      "p_retAceAgainst_a              0\n",
      "p_retAceAgainst_b              0\n",
      "p_ret1stWon_a                  0\n",
      "p_ret1stWon_b                  0\n",
      "p_ret2ndWon_a                  0\n",
      "p_ret2ndWon_b                  0\n",
      "p_ret2ndWon_inPlay_a           0\n",
      "p_ret2ndWon_inPlay_b           0\n",
      "p_bpConv_a                     0\n",
      "p_bpConv_b                     0\n",
      "p_totalPtsWon_a                0\n",
      "p_totalPtsWon_b                0\n",
      "dominance_ratio_a              0\n",
      "dominance_ratio_b              0\n",
      "elo_a                          0\n",
      "elo_b                          0\n",
      "elo_surface_a                  0\n",
      "elo_surface_b                  0\n",
      "total_matches_a                0\n",
      "total_matches_b                0\n",
      "total_surface_matches_a        0\n",
      "total_surface_matches_b        0\n",
      "recent_matches_a               0\n",
      "recent_matches_b               0\n",
      "recent_minutes_a               0\n",
      "recent_minutes_b               0\n",
      "hth_win_p_a                    0\n",
      "hth_matches                    0\n",
      "form_delta_a                   0\n",
      "form_delta_b                   0\n",
      "elo_momentum_a                 0\n",
      "elo_momentum_b                 0\n",
      "name_a_new                     0\n",
      "name_b_new                     0\n",
      "old_winner                     0\n",
      "old_loser                      0\n",
      "merge_date                     0\n",
      "surface_norm                   0\n",
      "best_of_norm                   0\n",
      "ATP                            0\n",
      "Location                       0\n",
      "Tournament                     0\n",
      "Date                           0\n",
      "Series                         0\n",
      "Court                          0\n",
      "Surface                        0\n",
      "Round                          0\n",
      "Best of                        0\n",
      "winner_new                     0\n",
      "loser_new                      0\n",
      "WRank                          0\n",
      "LRank                          0\n",
      "W1                             3\n",
      "L1                             2\n",
      "W2                           332\n",
      "L2                           331\n",
      "W3                         23453\n",
      "L3                         23453\n",
      "W4                         40065\n",
      "L4                         40065\n",
      "W5                         42658\n",
      "L5                         42658\n",
      "Wsets                          2\n",
      "Lsets                          3\n",
      "Comment                        0\n",
      "CBW                        30290\n",
      "CBL                        30290\n",
      "GBW                        39767\n",
      "GBL                        39767\n",
      "IWW                        33151\n",
      "IWL                        33151\n",
      "SBW                        39601\n",
      "SBL                        39601\n",
      "B365W                       4074\n",
      "B365L                       4065\n",
      "B&WW                       43325\n",
      "B&WL                       43325\n",
      "EXW                        18348\n",
      "EXL                        18344\n",
      "PSW                         8495\n",
      "PSL                         8495\n",
      "WPts                       10355\n",
      "LPts                       10355\n",
      "UBW                        37377\n",
      "UBL                        37377\n",
      "LBW                        27056\n",
      "LBL                        27052\n",
      "SJW                        34960\n",
      "SJL                        34958\n",
      "MaxW                       19093\n",
      "MaxL                       19093\n",
      "AvgW                       19093\n",
      "AvgL                       19093\n"
     ]
    }
   ],
   "source": [
    "merged_df = merge_old_new(sackman_df, odds_df)\n",
    "\n",
    "og_rows = odds_df.shape[0]\n",
    "merged_rows = merged_df.shape[0]\n",
    "\n",
    "print(\"rows in sackman_df\", og_rows)\n",
    "print(\"rows in merged_df\", merged_rows)\n",
    "print(\"percent lost\", (og_rows - merged_rows) / og_rows)\n",
    "\n",
    "print(merged_df.isnull().sum().to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a81603",
   "metadata": {},
   "source": [
    "With the current merged dataframe, there are many columns that the model does not use for features or backtesting. These can be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "93c85e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "draw_size                             0\n",
      "best_of                               0\n",
      "hth_win_p_a                           0\n",
      "CBW                               30290\n",
      "CBL                               30290\n",
      "                                  ...  \n",
      "log_total_surface_matches_diff        0\n",
      "log_recent_matches_diff               0\n",
      "inv_rank_diff                         0\n",
      "log_hth_matches                   23269\n",
      "result                                0\n",
      "Length: 83, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from typing import Any\n",
    "\n",
    "\n",
    "columns_to_drop = [\n",
    "    # merge helper\n",
    "    \"name_a_new\",\"name_b_new\",\"old_winner\",\"old_loser\",\n",
    "    \"merge_date\",\"surface_norm\",\"best_of_norm\",\n",
    "\n",
    "    # odds metadata\n",
    "    \"ATP\",\"Location\",\"Tournament\",\"Date\",\"Series\",\"Court\",\"Surface\",\n",
    "    \"Round\",\"Best of\",\"winner_new\",\"loser_new\",\"WRank\",\"LRank\",\n",
    "    \"W1\",\"L1\",\"W2\",\"L2\",\"W3\",\"L3\",\"W4\",\"L4\",\"W5\",\"L5\",\"Wsets\",\"Lsets\",\"Comment\",\n",
    "\n",
    "    # sackmann identifiers\n",
    "    \"name_a\",\"name_b\",\"id_a\",\"id_b\",\"score\",\"tourney_date\",\"minutes\",\n",
    "\n",
    "    # raw stats A\n",
    "    \"ace_a\",\"df_a\",\"svpt_a\",\"1stIn_a\",\"1stWon_a\",\"2ndWon_a\",\"SvGms_a\",\"bpSaved_a\",\"bpFaced_a\",\n",
    "\n",
    "    # raw stats B\n",
    "    \"ace_b\",\"df_b\",\"svpt_b\",\"1stIn_b\",\"1stWon_b\",\"2ndWon_b\",\"SvGms_b\",\"bpSaved_b\",\"bpFaced_b\",\n",
    "]\n",
    "\n",
    "backtest_df = merged_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "backtest_df.columns\n",
    "\n",
    "import sys, os\n",
    "\n",
    "PROJECT_ROOT = os.path.abspath(\"../..\")\n",
    "SRC_ROOT = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_ROOT not in sys.path:\n",
    "    sys.path.insert(0, SRC_ROOT)\n",
    "\n",
    "from atp_forecaster.training_data.build_dataset_v1 import one_hot_encode\n",
    "from atp_forecaster.training_data.build_dataset_v1 import build_matchup_features\n",
    "\n",
    "backtest_df = one_hot_encode(backtest_df)\n",
    "backtest_df = build_matchup_features(backtest_df)\n",
    "\n",
    "backtest_df = backtest_df[[col for col in backtest_df.columns if col != 'result'] + ['result']]\n",
    "\n",
    "bool_cols = backtest_df.select_dtypes(include=['bool']).columns\n",
    "backtest_df[bool_cols] = backtest_df[bool_cols].astype(int)\n",
    "\n",
    "print(backtest_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f44254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
