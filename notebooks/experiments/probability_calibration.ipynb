{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33c548c",
   "metadata": {},
   "source": [
    "## Probability Calibration\n",
    "\n",
    "The goal of this notebook is to investigate the accuracy of the model's reported probabilities. Methods of calibrating models will also be explored.\n",
    "\n",
    "One method to visualise the accuracy of probabilities is to use a calibration curve. A calibration curve plots observed frequency against the predicited probability. If a model's prediction matches reality perfectly, the curve should be a perfect y = x line.\n",
    "\n",
    "To quantify the model calibration, ECE and Brier score is measured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93021752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dataset\n",
    "import sys, os\n",
    "\n",
    "# Project root: /Users/jaydenshi/Documents/Code/Projects/atp-forecaster\n",
    "PROJECT_ROOT = os.path.abspath(\"../..\")\n",
    "\n",
    "# Add src/ to sys.path so `atp_forecaster` is importable\n",
    "SRC_ROOT = os.path.join(PROJECT_ROOT, \"src\")\n",
    "if SRC_ROOT not in sys.path:\n",
    "    sys.path.insert(0, SRC_ROOT)\n",
    "\n",
    "from atp_forecaster.data import load_processed\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = load_processed()\n",
    "X.drop(columns=['recent_minutes_diff',\n",
    "       'log_total_surface_matches_diff',\n",
    "       'log_recent_matches_diff'])\n",
    "\n",
    "test_size = 0.4\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb8de72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import CalibrationDisplay\n",
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "def produce_calibration_curve(model, x_train, x_test, y_train, y_test, n_bins=50):\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Predicted probabilities for positive class\n",
    "    y_proba = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    brier = brier_score_loss(y_test, y_proba)\n",
    "\n",
    "    # ECE\n",
    "    # Bin predictions into n_bins uniformly over [0, 1]\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    bin_ids = np.digitize(y_proba, bins) - 1\n",
    "\n",
    "    ece = 0.0\n",
    "    N = len(y_test)\n",
    "\n",
    "    for k in range(n_bins):\n",
    "        mask = bin_ids == k\n",
    "        if not np.any(mask):\n",
    "            continue\n",
    "\n",
    "        pk = y_proba[mask].mean()\n",
    "        fk = y_test[mask].mean()      \n",
    "        wk = mask.sum() / N           \n",
    "\n",
    "        ece += wk * abs(pk - fk)\n",
    "\n",
    "    print(f\"Brier score: {brier:.4f}\")\n",
    "    print(f\"ECE (n_bins={n_bins}): {ece:.4f}\")\n",
    "\n",
    "    disp = CalibrationDisplay.from_predictions(\n",
    "        y_test,\n",
    "        y_proba,\n",
    "        n_bins=n_bins,\n",
    "        strategy=\"uniform\"\n",
    "    )\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Calibration curve\")\n",
    "    ax.grid(True)\n",
    "\n",
    "    # annotate metrics on the plot\n",
    "    text = f\"Brier: {brier:.4f}\\nECE: {ece:.4f}\"\n",
    "    ax.text(0.05, 0.95, text, transform=ax.transAxes,\n",
    "            va='top', ha='left', fontsize=9,\n",
    "            bbox=dict(boxstyle=\"round\", alpha=0.1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return brier, ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c39f74c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Pipeline is not fitted yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:53\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:903\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    902\u001b[39m         Xt = transform.transform(Xt)\n\u001b[32m--> \u001b[39m\u001b[32m903\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/sklearn.py:1918\u001b[39m, in \u001b[36mXGBClassifier.predict_proba\u001b[39m\u001b[34m(self, X, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m class_prob\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m class_probs = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1919\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidate_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1921\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_margin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1922\u001b[39m \u001b[43m    \u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m=\u001b[49m\u001b[43miteration_range\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1923\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1924\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _cls_predict_proba(\u001b[38;5;28mself\u001b[39m.n_classes_, class_probs, np.vstack)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/core.py:774\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    773\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/sklearn.py:1443\u001b[39m, in \u001b[36mXGBModel.predict\u001b[39m\u001b[34m(self, X, output_margin, validate_features, base_margin, iteration_range)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1443\u001b[39m     predts = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_booster\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.inplace_predict(\n\u001b[32m   1444\u001b[39m         data=X,\n\u001b[32m   1445\u001b[39m         iteration_range=iteration_range,\n\u001b[32m   1446\u001b[39m         predict_type=\u001b[33m\"\u001b[39m\u001b[33mmargin\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_margin \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1447\u001b[39m         missing=\u001b[38;5;28mself\u001b[39m.missing,\n\u001b[32m   1448\u001b[39m         base_margin=base_margin,\n\u001b[32m   1449\u001b[39m         validate_features=validate_features,\n\u001b[32m   1450\u001b[39m     )\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_cupy_alike(predts):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/xgboost/sklearn.py:1009\u001b[39m, in \u001b[36mXGBModel.get_booster\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1007\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m NotFittedError\n\u001b[32m-> \u001b[39m\u001b[32m1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mneed to call fit or load_model beforehand\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._Booster\n",
      "\u001b[31mNotFittedError\u001b[39m: need to call fit or load_model beforehand",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m../../models/xgb_v1.pkl\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      5\u001b[39m     model = clone(pickle.load(f))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mproduce_calibration_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m, in \u001b[36mproduce_calibration_curve\u001b[39m\u001b[34m(model, x_train, x_test, y_train, y_test, n_bins)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mproduce_calibration_curve\u001b[39m(model, x_train, x_test, y_train, y_test, n_bins=\u001b[32m50\u001b[39m):\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# model.fit(x_train, y_train)\u001b[39;00m\n\u001b[32m      8\u001b[39m \n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m# Predicted probabilities for positive class\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     y_proba = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m[:, \u001b[32m1\u001b[39m]\n\u001b[32m     12\u001b[39m     brier = brier_score_loss(y_test, y_proba)\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# ECE\u001b[39;00m\n\u001b[32m     15\u001b[39m     \u001b[38;5;66;03m# Bin predictions into n_bins uniformly over [0, 1]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:897\u001b[39m, in \u001b[36mPipeline.predict_proba\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform the data, and apply `predict_proba` with the final estimator.\u001b[39;00m\n\u001b[32m    861\u001b[39m \n\u001b[32m    862\u001b[39m \u001b[33;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    894\u001b[39m \u001b[33;03m    Result of calling `predict_proba` on the final estimator.\u001b[39;00m\n\u001b[32m    895\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    896\u001b[39m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m897\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_raise_or_warn_if_not_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_routing_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    156\u001b[39m     value = typ()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    163\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/pipeline.py:55\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mPipeline is not fitted yet.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Pipeline is not fitted yet."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.base import clone\n",
    "\n",
    "with open(\"../../models/xgb_v1.pkl\", \"rb\") as f:\n",
    "    model = clone(pickle.load(f))\n",
    "\n",
    "produce_calibration_curve(model, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6f96a",
   "metadata": {},
   "source": [
    "The calibration curve closely resembes the y=x line, meaning the model is already quite accurate in its probability predictions. \n",
    "\n",
    "The Brier and ECE scores are also within an acceptable range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1756512",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
