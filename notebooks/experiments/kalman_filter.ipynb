{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c08b833",
   "metadata": {},
   "source": [
    "## Kalman Filter\n",
    "The aim of this notebook is to understand and experiment with Kalman Filters, as a potential improvement upon the current glicko-2 rating system.\n",
    "\n",
    "### 1. Background\n",
    "**Assumptions**\n",
    "\n",
    "A Kalman filter estimates something that cannot be observed directly. It does so by using:\n",
    "1. A model of how the target quantity evolves over time\n",
    "2. Noisy samples of the target quantity\n",
    "\n",
    "The KF then maintains a belief about the hidden state.\n",
    "\n",
    "The KF assumes that the hidden state evolves over time, $$x_t = Fx_{t-1} + w_t$$ \n",
    "\n",
    "where, F is a transition matrix and $w_t$ is a gaussian process noise.\n",
    "\n",
    "We also assume that our observations are noisy, $$y_t = Hx_t + v_t$$ \n",
    "\n",
    "where, H is an observation matrix, that relates the inner state to our observation. $y_t$ is the observed performance, and $v_t$ is a gaussian observation noise.\n",
    "\n",
    "**Updates**\n",
    "\n",
    "The updates occur in two steps.\n",
    "\n",
    "First we build the prior. We estimate our state to be \n",
    "$$\\hat{x}_{t|t-1} = F\\hat{x}_{t-1}.$$ \n",
    "\n",
    "Our uncertainty grows from the previous observation, \n",
    "$$P_{t|t-1} = FP_{t-1}F^T + Q.$$\n",
    "\n",
    "Next, we update the understanding with new information. The Kalman Gain, $K_t$, denotes how much the new observation should be trusted vs the prior, given by $$K_t = P_{t|t-1}H^T(HP_{t|t-1}H^T + R)^{-1}.$$\n",
    "\n",
    "Based on this Kalman Gain, we update the state and uncertainty:\n",
    "$$\\hat{x_{t}} = \\hat{x}_{t|t-1} + K_t(y_t - H\\hat{x}_{t|t-1})$$\n",
    "$$P_t = (I - K_tH)P_{t|t-1}$$\n",
    "\n",
    "Overall, if the uncertainty is high, we trust new data more. If uncertainty is low, we trust the prior more. Each observation also reduces the uncertainty.\n",
    "\n",
    "### 2. State Construction\n",
    "\n",
    "In traditional Elo or Glicko-2 skill measurement techniques, the true skill is a number that moves up or down based only on match results and uncertainty. In reality, the result of a match is a noisy measurement of a player's underlying ability, and is influenced by many other factors, including fatigue, surface preference and more.\n",
    "\n",
    "The simplest state that represents an observation is to include the true skill of both players:\n",
    "$$x = [s_a, s_b]^T, \\space P = \\begin{bmatrix} P_A & 0 \\\\ 0 & P_B \\end{bmatrix}$$\n",
    "\n",
    "Then we propose that true skill is a gaussian random walk: $$s_t=s_{t-1} + w_t,\\space w_t \\sim N(0, q)$$\n",
    "\n",
    "The prior hence is constructed as:\n",
    "$$x^- = x$$\n",
    "$$P^- = P + Q = \\begin{bmatrix} P_A + q & 0 \\\\ 0 & P_B + q \\end{bmatrix}$$\n",
    "\n",
    "Here we assume the match result is solely driven by the skill difference between the two players. We model the probability that player A wins the match as\n",
    "$$\\hat{y}^- = h(x^-)$$\n",
    "where we use the logistic elo function\n",
    "$$h(x) = (1+\\exp(-k\\begin{bmatrix} 1 & -1 \\end{bmatrix}x))^{-1}$$\n",
    "\n",
    "However, because $h(x)$ is non linear, we should use the Extended Kalman Filter, and approximate h(x) with the taylor expansion. We thus have,\n",
    "\n",
    "$$ h(x) \\approx  h(x^-) + H(x - x^-)$$\n",
    "where $H$ is the Jacobian of $h$ evaluated at $x^-$,\n",
    "\n",
    "$$H = kp^-(1-p^-)\\begin{bmatrix} 1 & -1\\end{bmatrix},\\space p^-=h(x^-).$$\n",
    "\n",
    "Using the above formulas, we compute the Kalman Gain:\n",
    "$$S=HP^-H^T + R$$\n",
    "$$K = P^-H^TS^{-1}$$\n",
    "\n",
    "Here $R$ represents the noise from the result of the match. Because we approximate the result with \n",
    "$$r \\approx h(x^-) + v, \\space v \\sim N(0, R).$$\n",
    "\n",
    "Because $r \\sim Bern(\\hat{y}^-)$, a natural choice of $R$ is $R = \\hat{y}^-(1-\\hat{y}^-)$ to approximate the Bernoulli observation noise by a Gaussian with the same variance.\n",
    "\n",
    "We then update the posterior\n",
    "$$x^+ = x^- + Ke, \\space e = r - \\hat{y}^-$$\n",
    "$$P^+ = (I - KH)P^-$$\n",
    "where $r$ is the result. 1 if A wins, 0 if A loses.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3958c0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
